"""Sink integrations for data-cli"""

import sqlite3
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Optional
from jinja2 import Template
from rich.console import Console

console = Console()


def save_to_sqlite(df: pd.DataFrame, database_file: str, table_name: str) -> bool:
    """Save DataFrame to SQLite database."""
    try:
        # Ensure directory exists
        db_path = Path(database_file)
        db_path.parent.mkdir(parents=True, exist_ok=True)
        
        conn = sqlite3.connect(database_file)
        df.to_sql(table_name, conn, if_exists='replace', index=False)
        conn.close()
        
        console.print(f"[green]✓[/green] Saved {len(df)} rows to {database_file}::{table_name}")
        return True
    except Exception as e:
        console.print(f"[red]✗[/red] Error saving to SQLite: {e}")
        return False


def save_to_excel(df: pd.DataFrame, output_dir: str, filename: Optional[str] = None) -> bool:
    """Save DataFrame to Excel file."""
    try:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        if not filename:
            filename = "export.xlsx"
        
        filepath = output_path / filename
        df.to_excel(filepath, index=False, engine='openpyxl')
        
        console.print(f"[green]✓[/green] Saved {len(df)} rows to {filepath}")
        return True
    except Exception as e:
        console.print(f"[red]✗[/red] Error saving to Excel: {e}")
        return False


def generate_snowflake_sql(df: pd.DataFrame, sink_config: Dict[str, Any], table_name: Optional[str] = None) -> str:
    """Generate Snowflake SQL script to load the DataFrame."""
    
    # Infer column types from DataFrame
    column_defs = []
    for col, dtype in df.dtypes.items():
        if dtype == 'int64':
            sql_type = 'INTEGER'
        elif dtype == 'float64':
            sql_type = 'FLOAT'
        elif dtype == 'bool':
            sql_type = 'BOOLEAN'
        elif dtype == 'datetime64[ns]':
            sql_type = 'TIMESTAMP_NTZ'
        else:
            sql_type = 'VARCHAR(16777216)'  # Snowflake default VARCHAR max
        
        # Clean column name for SQL
        clean_col = col.replace(' ', '_').replace('-', '_').replace('.', '_')
        column_defs.append(f"    {clean_col} {sql_type}")
    
    # Get sink config
    role = sink_config.get('role', 'ANALYST')
    warehouse = sink_config.get('warehouse', 'COMPUTE_WH')
    database = sink_config.get('database', 'HACKATHON_DB')
    schema = sink_config.get('schema', 'PUBLIC')
    table = table_name or sink_config.get('table_name', 'LOADED_DATA')
    
    # Generate SQL template
    sql_template = Template("""-- Snowflake Load Script
-- Generated by data-cli

USE ROLE {{ role }};
USE WAREHOUSE {{ warehouse }};
USE DATABASE {{ database }};
USE SCHEMA {{ schema }};

-- Create table if not exists
CREATE TABLE IF NOT EXISTS {{ table }} (
{{ column_defs }}
);

-- Insert data (example - adjust based on your staging area)
-- COPY INTO {{ table }}
-- FROM @your_stage/data.csv
-- FILE_FORMAT = (TYPE = CSV, SKIP_HEADER = 1);

-- Or use INSERT statements for small datasets
-- INSERT INTO {{ table }} VALUES
-- {% for row in sample_rows %}
-- ({{ row }})
-- {% if not loop.last %},{% endif %}
-- {% endfor %}
;
""")
    
    sql = sql_template.render(
        role=role,
        warehouse=warehouse,
        database=database,
        schema=schema,
        table=table,
        column_defs=',\n'.join(column_defs)
    )
    
    return sql


def save_to_sink(df: pd.DataFrame, sink_name: str, sink_config: Dict[str, Any], **kwargs) -> bool:
    """Save DataFrame to the specified sink."""
    sink_type = sink_config.get('type', sink_name.lower())
    
    if sink_type == 'sqlite' or sink_name == 'powerbi':
        database_file = sink_config.get('database_file', './prod_dashboard.db')
        table_name = sink_config.get('table_name', 'data')
        return save_to_sqlite(df, database_file, table_name)
    
    elif sink_type == 'excel':
        output_dir = sink_config.get('output_dir', './client_exports/')
        filename = kwargs.get('filename')
        return save_to_excel(df, output_dir, filename)
    
    elif sink_type == 'snowflake' or sink_name == 'snowflake':
        # Generate SQL script
        table_name = kwargs.get('table_name') or sink_config.get('table_name', 'LOADED_DATA')
        sql = generate_snowflake_sql(df, sink_config, table_name)
        
        # Save to file
        output_file = f"load_to_{sink_name}.sql"
        with open(output_file, 'w') as f:
            f.write(sql)
        
        console.print(f"[green]✓[/green] Generated Snowflake SQL script: {output_file}")
        console.print(f"[dim]Preview:[/dim]")
        console.print(sql[:500] + "..." if len(sql) > 500 else sql)
        return True
    
    else:
        console.print(f"[red]✗[/red] Unknown sink type: {sink_type}")
        return False

